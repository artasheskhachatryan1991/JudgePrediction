{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import pyodbc\n",
    "\n",
    "def load_data(conn, table, is_train = True, train_decision_date = None, test_id = None):    \n",
    "    cursor = conn.cursor()       \n",
    "    sql = 'select * from dbo.load_' + table    \n",
    "    if table == 'CourtCase':\n",
    "        sql += '(?, ?)'\n",
    "        cursor.execute(sql, (test_id, train_decision_date))\n",
    "        rows = np.array(cursor.fetchall())\n",
    "        columns = np.array(cursor.description)[:, 0]            \n",
    "        assert len(rows) > 0, 'No data found for specified filters'\n",
    "    else:\n",
    "        sql += '(?)'\n",
    "        cursor.execute(sql, (test_id))\n",
    "        rows = np.array(cursor.fetchall())\n",
    "        columns = np.array(cursor.description)[:, 0]\n",
    "    return pd.DataFrame(data=list(rows), columns=columns)\n",
    "\n",
    "def load_all_data(conn, tables, is_train = True, train_decision_date = None, test_id = None):\n",
    "    try:\n",
    "        assert is_train or test_id != None\n",
    "    except AssertionError():\n",
    "        raise AssertionError(\"test_id must be passed in training mode\") \n",
    "    results = {}    \n",
    "    for table in tables:\n",
    "        results[table] = load_data(conn, table, is_train, train_decision_date, test_id)\n",
    "        print(f'{table} data has been processed')            \n",
    "    return results\n",
    "\n",
    "def data_preprocessing(data):\n",
    "    CourtCase = data[\"CourtCase\"]\n",
    "    CourtCaseParty = data[\"CourtCaseParty\"]\n",
    "    CourtCaseSchedule = data[\"CourtCaseSchedule\"]\n",
    "    CourtCaseCrimes = data[\"CourtCaseCrimes\"]\n",
    "    CourtCaseDocument = data[\"CourtCaseDocument\"]\n",
    "    CourtCasePartyLegalRepresentative = data[\"CourtCasePartyLegalRepresentative\"]\n",
    "    \n",
    "    CourtCase = CourtCase.sample(frac=1)\n",
    "\n",
    "    CourtCaseParty[\"IsNPPA\"] = CourtCaseParty.PartyID.apply(lambda x: 1 if x == -2 else 0)\n",
    "\n",
    "    ccp_aggregations = {}\n",
    "    ccp_aggregations[\"CourtCasePartyID\"] = {\"ccp_count\": \"count\"}\n",
    "    ccp_aggregations[\"IsNPPA\"] = {\"is_nppa_present\": \"max\"}\n",
    "\n",
    "    CourtCaseParty = CourtCaseParty.groupby(\"CourtCaseID\").agg({**ccp_aggregations})\n",
    "    CourtCaseParty.columns = CourtCaseParty.columns.droplevel(level=0)\n",
    "    CourtCase = pd.merge(CourtCase, CourtCaseParty, how='left', left_on=\"CourtCaseID\", right_index=True)\n",
    "    \n",
    "\n",
    "    ccsh_aggregations = {\"HearingDate\" : {\"min_hearingdate\": \"min\"}}\n",
    "    CourtCaseSchedule = CourtCaseSchedule.groupby(\"CourtCaseID\").agg({**ccsh_aggregations})\n",
    "    CourtCaseSchedule.columns = CourtCaseSchedule.columns.droplevel(level=0)\n",
    "    CourtCase = pd.merge(CourtCase, CourtCaseSchedule, how='left', left_on=\"CourtCaseID\", right_index=True)\n",
    "\n",
    "\n",
    "    CourtCaseCrimes = CourtCaseCrimes.groupby(\"CourtCaseID\").count()\n",
    "    CourtCase = pd.merge(CourtCase, CourtCaseCrimes, how='left', left_on=\"CourtCaseID\", right_index=True)\n",
    "\n",
    "    CourtCase = pd.merge(CourtCase, CourtCasePartyLegalRepresentative, how='left', left_on=\"CourtCaseID\", right_on=\"CourtCaseID\")\n",
    "\n",
    "\n",
    "    # CourtCaseAddmisibility = pd.read_csv(\"CourtCaseAddmisibility.csv\")\n",
    "    # ccai_aggregations = {\"AdmissibilityItemID\" : {\"cnt_admitem\" : \"count\"}}\n",
    "    # CourtCaseAddmisibility = CourtCaseAddmisibility.groupby(\"CourtCaseID\").agg({**ccai_aggregations})\n",
    "    # CourtCaseAddmisibility.columns = CourtCaseAddmisibility.columns.droplevel(level=0)\n",
    "    # CourtCase = pd.merge(CourtCase, CourtCaseAddmisibility, how='left', left_on=\"CourtCaseID\", right_index=True)    \n",
    "\n",
    "    # CourtCaseIssues = pd.read_csv(\"CourtCaseIssues.csv\")\n",
    "    # ccissues_aggregations = {\"CourtCaseIssuesToBeAnalysedID\" : {\"cnt_issues\" : \"count\"}}\n",
    "    # CourtCaseIssues = CourtCaseIssues.groupby(\"CourtCaseID\").agg({**ccissues_aggregations})\n",
    "    # CourtCaseIssues.columns = CourtCaseIssues.columns.droplevel(level=0)\n",
    "    # CourtCase = pd.merge(CourtCase, CourtCaseIssues, how='left', left_on=\"CourtCaseID\", right_index=True)    \n",
    "\n",
    "    CourtCaseDocument = pd.get_dummies(CourtCaseDocument, columns=[\"DocumentTypeID\"])\n",
    "\n",
    "    cc_doc_dum_agg = {}\n",
    "    dum_columns = [x for x in CourtCaseDocument.columns if x.startswith(\"DocumentTypeID\")]\n",
    "    for col in dum_columns:\n",
    "        cc_doc_dum_agg[col] = {col:\"sum\"}\n",
    "    ccdoc_aggregations = {\"Size\" : {\"total_size\" : \"sum\", \"avg_size\" : \"mean\"}}\n",
    "    CourtCaseDocument.Size = pd.to_numeric(CourtCaseDocument.Size)\n",
    "\n",
    "    CourtCaseDocument = CourtCaseDocument.groupby(\"CourtCaseID\").agg({**ccdoc_aggregations, **cc_doc_dum_agg})\n",
    "    CourtCaseDocument.columns = CourtCaseDocument.columns.droplevel(level=0)\n",
    "    CourtCase = pd.merge(CourtCase, CourtCaseDocument, how='left', left_on=\"CourtCaseID\", right_index=True)\n",
    "\n",
    "    [CourtCase[x].fillna(0, inplace=True) for x in CourtCase.columns if x.startswith(\"ArticleID\")];\n",
    "    CourtCase.CountOfLegalRepresentative.fillna(0, inplace=True)\n",
    "    CourtCase.ccp_count.fillna(0, inplace=True)\n",
    "    # CourtCase.cnt_admitem.fillna(0, inplace=True)\n",
    "    # CourtCase.cnt_issues.fillna(0, inplace=True)\n",
    "    CourtCase.is_nppa_present.fillna(0, inplace=True)        \n",
    "\n",
    "    CourtCase[\"HasRecieptDocument\"] = CourtCase.ReceiptDocumentID.fillna(0).apply(lambda x: 1 if x > 0 else 0)\n",
    "    CourtCase[\"HasProsecutionCase\"] = CourtCase.ProsecutionCaseID.fillna(0).apply(lambda x: 1 if x > 0 else 0)\n",
    "    # CourtCase[\"IsAppealedcase\"] = CourtCase.AppealedCourtCaseID.fillna(0).apply(lambda x: 1 if x > 0 else 0)\n",
    "    CourtCase[\"ColorID\"] = CourtCase.ColorID.fillna(-1)\n",
    "    CourtCase[\"InstanceLevelID\"] = CourtCase.InstanceLevelID.fillna(-1)\n",
    "    CourtCase[\"SubCategoryID\"] = CourtCase.SubCategoryID.fillna(-1)\n",
    "    CourtCase[\"CasePriorityID\"] = CourtCase.CasePriorityID.fillna(-1)\n",
    "    CourtCase[\"IsDetentionCase\"] = CourtCase.IsDetentionCase.fillna(0)\n",
    "    CourtCase[\"IsPublicCase\"] = CourtCase.IsPublicCase.fillna(0)\n",
    "    CourtCase[\"CommittedByMinor\"] = CourtCase.CommittedByMinor.fillna(0)\n",
    "    CourtCase[\"GenderBasedViolence\"] = CourtCase.GenderBasedViolence.fillna(0)\n",
    "    CourtCase[\"InitiatedFromAbunzi\"] = CourtCase.InitiatedFromAbunzi.fillna(0)\n",
    "    CourtCase[\"SolvedFromAbunzi\"] = CourtCase.SolvedFromAbunzi.fillna(0)\n",
    "    CourtCase[\"HasDetails\"] = CourtCase.HasDetails.fillna(0)\n",
    "    CourtCase[\"IsExempted\"] = CourtCase.IsExempted.fillna(0)\n",
    "    CourtCase[\"AttachedDate\"] = CourtCase.AttachedDate.fillna(0)\n",
    "    CourtCase.drop(columns=[\"HasPassedCaseNumberAllocated\", \"CaseCode\", \"MinorVersion\", \"MajorVersion\", \"CourtID\", \"CourtCaseID\"\n",
    "                       , \"ReceiptDocumentID\",  \"ProsecutionCaseID\", \"WFActionID\"\n",
    "                       , \"NotRegisteredCaseCode\", \"WFStateID\", \"UpdatedUserID\", \"OwnerUserID\", \"PublicOwnerUserId\", 'CreatedUserID'\n",
    "                       ,'AppealedCourtCaseID', \"CountOfJudgmentPages\"\n",
    "                      ], inplace=True)    \n",
    "  \n",
    "    drop_col = ['DecisionPronouncementDate', 'DecisionPronouncementDateYearID',\n",
    "       'ExecutionCaseApprovedUserID', 'PaymentBankID', 'LitigationCaseID',\n",
    "       'CaseRejectionID', 'ExtraOrdinaryProcedureID', 'PreviousCourtCaseID',\n",
    "       'SpecialCaseID']\n",
    "    CourtCase = CourtCase.drop(columns=drop_col)\n",
    "    CourtCase.dropna(inplace=True)\n",
    "    \n",
    "    assert len(CourtCase) > 0, 'No data left after preprocessing'    \n",
    "\n",
    "    X = CourtCase.drop(columns=[\"DecisionDuration\"])\n",
    "    Y = CourtCase[\"DecisionDuration\"]\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def get_connection(path):\n",
    "    cwd = os.getcwd()\n",
    "    with open(cwd + path) as f:\n",
    "        data = json.load(f)\n",
    "    conn = pyodbc.connect(\"DRIVER={{SQL Server}};SERVER={0}; database={1}; \\\n",
    "           trusted_connection=no;UID={2};PWD={3}\".format(data[\"server\"]\n",
    "                                                         , data[\"db\"]\n",
    "                                                         , data[\"login\"]\n",
    "                                                         , data[\"pass\"]))\n",
    "    return conn\n",
    "\n",
    "def parse_args_train(*argument_array):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--properties_path',\n",
    "                        default = '\\db_properties\\db_connection.json',\n",
    "                        help='relative path to database connection properties')\n",
    "    parser.add_argument('--train_decision_date',                        \n",
    "                        help='date until where to train the data')\n",
    "    args = parser.parse_args(*argument_array)\n",
    "    return args\n",
    "\n",
    "def parse_args_test(*argument_array):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--test_id',                        \n",
    "                        help='case id to test the duration', )    \n",
    "    args = parser.parse_args(*argument_array)\n",
    "    return args\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    TABLE_LIST = [\"CourtCase\", \"CourtCaseParty\", \"CourtCaseSchedule\"\n",
    "    , \"CourtCaseCrimes\", \"CourtCasePartyLegalRepresentative\", \"CourtCaseDocument\"]\n",
    "    PROPERTIES_PATH = args.properties_path\n",
    "    TRAIN_DECISION_DATE = args.train_decision_date\n",
    "\n",
    "    boost_params = {'n_estimators': 200,\n",
    " 'min_samples_split': 40,\n",
    " 'min_samples_leaf': 4,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 20,\n",
    " 'learning_rate': 0.05}\n",
    "    boost = GradientBoostingRegressor(**boost_params)\n",
    "\n",
    "    train_data = load_all_data(get_connection(PROPERTIES_PATH), TABLE_LIST, is_train=True, train_decision_date=TRAIN_DECISION_DATE)\n",
    "    train_data = data_preprocessing(train_data)\n",
    "    train_X, train_Y = train_data\n",
    "    boost.fit(X, Y)\n",
    "\n",
    "    print(\"training has been completed succesfully !!!!\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    \n",
    "    while True:\n",
    "        args = parse_args_test()\n",
    "        TEST_ID = args.test_id\n",
    "\n",
    "        test_data = load_all_data(get_connection(PROPERTIES_PATH), TABLE_LIST, is_train=False, train_decision_date=None, test_id=TEST_ID)\n",
    "        test_data = data_preprocessing(test_data)\n",
    "        test_X, test_Y = test_data\n",
    "\n",
    "        missing_cols = set(train_X.columns ) - set(test_X.columns )\n",
    "        # Add a missing column in test set with default value equal to 0\n",
    "        for c in missing_cols:\n",
    "            test_X[c] = 0\n",
    "        # Ensure the order of column in the test set is in the same order than in train set\n",
    "        test_X = test_X[train_X.columns]\n",
    "        y_pred = boost.predict(test_X)[0]\n",
    "\n",
    "        print(\"predicted duration is %f days\" % y_pred)\n",
    "        print(\"actual duration is %f days\" % test_Y)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args_train()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter CaseID to test the duration116448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'116448'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input(\"enter CaseID to test the duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36-64\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CaseSubmittedDate</th>\n",
       "      <th>CaseRegisteredDate</th>\n",
       "      <th>CasePriorityID</th>\n",
       "      <th>CourtPresidentUserID</th>\n",
       "      <th>ChiefRegistrarUserID</th>\n",
       "      <th>AssignedRegistrarUserID</th>\n",
       "      <th>AssignedJudgeUserID</th>\n",
       "      <th>IsExempted</th>\n",
       "      <th>InitiatedFromAbunzi</th>\n",
       "      <th>SolvedFromAbunzi</th>\n",
       "      <th>...</th>\n",
       "      <th>DocumentTypeID_53.0</th>\n",
       "      <th>DocumentTypeID_54.0</th>\n",
       "      <th>DocumentTypeID_55.0</th>\n",
       "      <th>DocumentTypeID_56.0</th>\n",
       "      <th>DocumentTypeID_57.0</th>\n",
       "      <th>DocumentTypeID_58.0</th>\n",
       "      <th>DocumentTypeID_59.0</th>\n",
       "      <th>DocumentTypeID_60.0</th>\n",
       "      <th>HasRecieptDocument</th>\n",
       "      <th>HasProsecutionCase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43128</td>\n",
       "      <td>43135</td>\n",
       "      <td>1</td>\n",
       "      <td>7988</td>\n",
       "      <td>7996</td>\n",
       "      <td>8004</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CaseSubmittedDate  CaseRegisteredDate  CasePriorityID  \\\n",
       "0              43128               43135               1   \n",
       "\n",
       "   CourtPresidentUserID  ChiefRegistrarUserID  AssignedRegistrarUserID  \\\n",
       "0                  7988                  7996                     8004   \n",
       "\n",
       "   AssignedJudgeUserID  IsExempted  InitiatedFromAbunzi  SolvedFromAbunzi  \\\n",
       "0                   20           1                    0                 0   \n",
       "\n",
       "         ...          DocumentTypeID_53.0  DocumentTypeID_54.0  \\\n",
       "0        ...                            0                    0   \n",
       "\n",
       "   DocumentTypeID_55.0  DocumentTypeID_56.0  DocumentTypeID_57.0  \\\n",
       "0                    0                    0                    0   \n",
       "\n",
       "   DocumentTypeID_58.0  DocumentTypeID_59.0  DocumentTypeID_60.0  \\\n",
       "0                    0                    0                    0   \n",
       "\n",
       "   HasRecieptDocument HasProsecutionCase  \n",
       "0                   1                  0  \n",
       "\n",
       "[1 rows x 89 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[\"AssignedJudgeUserID\"] = 20\n",
    "test_X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
