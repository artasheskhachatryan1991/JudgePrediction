{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file CourtCase.sql has been processed\n",
      "file CourtCaseCrimes.sql has been processed\n",
      "file CourtCaseDocument.sql has been processed\n",
      "file CourtCaseParty.sql has been processed\n",
      "file CourtCasePartyLegalRepresentative.sql has been processed\n",
      "file CourtCaseSchedule.sql has been processed\n",
      "file CourtCase_test.sql has been processed\n"
     ]
    }
   ],
   "source": [
    "def calculate_missing_values(df):\n",
    "    missing_values_count = df.isnull().sum()\n",
    "    missing_values_pers = 100 * missing_values_count / len(df)\n",
    "\n",
    "    # Make a table with the results\n",
    "    mis_val_table = pd.concat([missing_values_count, missing_values_pers], axis=1)\n",
    "\n",
    "    # Rename the columns\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(columns={0: 'Missing Values', 1: '% of Total Values'})\n",
    "\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "\n",
    "    print(\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"\n",
    "                                                              \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "          \" columns that have missing values.\")\n",
    "\n",
    "    return mis_val_table_ren_columns\n",
    "\n",
    "cwd = os.getcwd()\n",
    "cwd = cwd.replace(\" - Copy\", \"\")\n",
    "# print(cwd + '\\db_properties\\db_connection.json')\n",
    "with open(cwd + '\\db_properties\\db_connection.json') as f:\n",
    "    data = json.load(f)\n",
    "conn = pyodbc.connect(\"DRIVER={{SQL Server}};SERVER={0}; database={1}; \\\n",
    "       trusted_connection=no;UID={2};PWD={3}\".format(data[\"server\"]\n",
    "                                                     , data[\"db\"]\n",
    "                                                     , data[\"login\"]\n",
    "                                                     , data[\"pass\"]))\n",
    "cursor = conn.cursor()\n",
    "script_path = cwd + '\\scripts'\n",
    "file_list = [\"CourtCase.sql\", \"CourtCase_test.sql\", \"CourtCaseParty.sql\", \"CourtCaseSchedule.sql\"\n",
    "    , \"CourtCaseCrimes.sql\", \"CourtCasePartyLegalRepresentative.sql\", \"CourtCaseDocument.sql\"]\n",
    "datas = []\n",
    "for script in os.listdir(script_path):\n",
    "    if script.endswith(\".sql\") and script in file_list:\n",
    "        file = script_path + \"\\\\\" + script\n",
    "        with open(file) as s:\n",
    "            sql = s.read()\n",
    "            cursor.execute(sql)\n",
    "            rows = np.array(cursor.fetchall())\n",
    "            columns = np.array(cursor.description)[:, 0]\n",
    "            datas.append(pd.DataFrame(data=rows, columns=columns))\n",
    "            print('file', script,  'has been processed')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "CourtCase, CourtCaseCrimes, CourtCaseDocument, CourtCaseParty, CourtCasePartyLegalRepresentative \\\n",
    "    , CourtCaseSchedule, CourtCase_test = datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36-64\\lib\\site-packages\\pandas\\core\\groupby.py:4291: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2359, 114)\n",
      "(15832, 114)\n",
      "(2359, 99)\n",
      "(15832, 99)\n",
      "Your selected dataframe has 99 columns.\n",
      "There are 69 columns that have missing values.\n",
      "(2345, 90)\n",
      "(15762, 90)\n",
      "Your selected dataframe has 90 columns.\n",
      "There are 0 columns that have missing values.\n",
      "Your selected dataframe has 90 columns.\n",
      "There are 0 columns that have missing values.\n",
      "(15762, 89) (15762,)\n",
      "(2345, 89) (2345,)\n"
     ]
    }
   ],
   "source": [
    "CourtCase = CourtCase.sample(frac=1)\n",
    "\n",
    "CourtCaseParty[\"IsNPPA\"] = CourtCaseParty.PartyID.apply(lambda x: 1 if x == -2 else 0)\n",
    "\n",
    "ccp_aggregations = {}\n",
    "ccp_aggregations[\"CourtCasePartyID\"] = {\"ccp_count\": \"count\"}\n",
    "ccp_aggregations[\"IsNPPA\"] = {\"is_nppa_present\": \"max\"}\n",
    "\n",
    "CourtCaseParty = CourtCaseParty.groupby(\"CourtCaseID\").agg({**ccp_aggregations})\n",
    "CourtCaseParty.columns = CourtCaseParty.columns.droplevel(level=0)\n",
    "CourtCase = pd.merge(CourtCase, CourtCaseParty, how='left', left_on=\"CourtCaseID\", right_index=True)\n",
    "CourtCase_test = pd.merge(CourtCase_test, CourtCaseParty, how='left', left_on=\"CourtCaseID\", right_index=True)\n",
    "\n",
    "ccsh_aggregations = {\"HearingDate\" : {\"min_hearingdate\": \"min\"}}\n",
    "CourtCaseSchedule = CourtCaseSchedule.groupby(\"CourtCaseID\").agg({**ccsh_aggregations})\n",
    "CourtCaseSchedule.columns = CourtCaseSchedule.columns.droplevel(level=0)\n",
    "CourtCase = pd.merge(CourtCase, CourtCaseSchedule, how='left', left_on=\"CourtCaseID\", right_index=True)\n",
    "CourtCase_test = pd.merge(CourtCase_test, CourtCaseSchedule, how='left', left_on=\"CourtCaseID\", right_index=True)\n",
    "\n",
    "CourtCaseCrimes = CourtCaseCrimes.groupby(\"CourtCaseID\").count()\n",
    "CourtCase = pd.merge(CourtCase, CourtCaseCrimes, how='left', left_on=\"CourtCaseID\", right_index=True)\n",
    "CourtCase_test = pd.merge(CourtCase_test, CourtCaseCrimes, how='left', left_on=\"CourtCaseID\", right_index=True)\n",
    "\n",
    "CourtCase = pd.merge(CourtCase, CourtCasePartyLegalRepresentative, how='left', left_on=\"CourtCaseID\", right_on=\"CourtCaseID\")\n",
    "CourtCase_test = pd.merge(CourtCase_test, CourtCasePartyLegalRepresentative, how='left', left_on=\"CourtCaseID\", right_on=\"CourtCaseID\")\n",
    "\n",
    "# CourtCaseAddmisibility = pd.read_csv(\"CourtCaseAddmisibility.csv\")\n",
    "# ccai_aggregations = {\"AdmissibilityItemID\" : {\"cnt_admitem\" : \"count\"}}\n",
    "# CourtCaseAddmisibility = CourtCaseAddmisibility.groupby(\"CourtCaseID\").agg({**ccai_aggregations})\n",
    "# CourtCaseAddmisibility.columns = CourtCaseAddmisibility.columns.droplevel(level=0)\n",
    "# CourtCase = pd.merge(CourtCase, CourtCaseAddmisibility, how='left', left_on=\"CourtCaseID\", right_index=True)\n",
    "# CourtCase_test = pd.merge(CourtCase_test, CourtCaseAddmisibility, how='left', left_on=\"CourtCaseID\", right_index=True)\n",
    "\n",
    "# CourtCaseIssues = pd.read_csv(\"CourtCaseIssues.csv\")\n",
    "# ccissues_aggregations = {\"CourtCaseIssuesToBeAnalysedID\" : {\"cnt_issues\" : \"count\"}}\n",
    "# CourtCaseIssues = CourtCaseIssues.groupby(\"CourtCaseID\").agg({**ccissues_aggregations})\n",
    "# CourtCaseIssues.columns = CourtCaseIssues.columns.droplevel(level=0)\n",
    "# CourtCase = pd.merge(CourtCase, CourtCaseIssues, how='left', left_on=\"CourtCaseID\", right_index=True)\n",
    "# CourtCase_test = pd.merge(CourtCase_test, CourtCaseIssues, how='left', left_on=\"CourtCaseID\", right_index=True)\n",
    "\n",
    "CourtCaseDocument = pd.get_dummies(CourtCaseDocument, columns=[\"DocumentTypeID\"])\n",
    "\n",
    "cc_doc_dum_agg = {}\n",
    "dum_columns = [x for x in CourtCaseDocument.columns if x.startswith(\"DocumentTypeID\")]\n",
    "for col in dum_columns:\n",
    "    cc_doc_dum_agg[col] = {col:\"sum\"}\n",
    "ccdoc_aggregations = {\"Size\" : {\"total_size\" : \"sum\", \"avg_size\" : \"mean\"}}\n",
    "CourtCaseDocument.Size = pd.to_numeric(CourtCaseDocument.Size)\n",
    "\n",
    "CourtCaseDocument = CourtCaseDocument.groupby(\"CourtCaseID\").agg({**ccdoc_aggregations, **cc_doc_dum_agg})\n",
    "CourtCaseDocument.columns = CourtCaseDocument.columns.droplevel(level=0)\n",
    "CourtCase = pd.merge(CourtCase, CourtCaseDocument, how='left', left_on=\"CourtCaseID\", right_index=True)\n",
    "CourtCase_test = pd.merge(CourtCase_test, CourtCaseDocument, how='left', left_on=\"CourtCaseID\", right_index=True)\n",
    "\n",
    "[CourtCase[x].fillna(0, inplace=True) for x in CourtCase.columns if x.startswith(\"ArticleID\")];\n",
    "CourtCase.CountOfLegalRepresentative.fillna(0, inplace=True)\n",
    "CourtCase.ccp_count.fillna(0, inplace=True)\n",
    "# CourtCase.cnt_admitem.fillna(0, inplace=True)\n",
    "# CourtCase.cnt_issues.fillna(0, inplace=True)\n",
    "CourtCase.is_nppa_present.fillna(0, inplace=True)\n",
    "\n",
    "[CourtCase_test[x].fillna(0, inplace=True) for x in CourtCase_test.columns if x.startswith(\"ArticleID\")];\n",
    "CourtCase_test.CountOfLegalRepresentative.fillna(0, inplace=True)\n",
    "CourtCase_test.ccp_count.fillna(0, inplace=True)\n",
    "# CourtCase_test.cnt_admitem.fillna(0, inplace=True)\n",
    "# CourtCase_test.cnt_issues.fillna(0, inplace=True)\n",
    "CourtCase_test.is_nppa_present.fillna(0, inplace=True)\n",
    "\n",
    "print(CourtCase_test.shape)\n",
    "print(CourtCase.shape)\n",
    "\n",
    "CourtCase[\"HasRecieptDocument\"] = CourtCase.ReceiptDocumentID.fillna(0).apply(lambda x: 1 if x > 0 else 0)\n",
    "CourtCase[\"HasProsecutionCase\"] = CourtCase.ProsecutionCaseID.fillna(0).apply(lambda x: 1 if x > 0 else 0)\n",
    "# CourtCase[\"IsAppealedcase\"] = CourtCase.AppealedCourtCaseID.fillna(0).apply(lambda x: 1 if x > 0 else 0)\n",
    "CourtCase[\"ColorID\"] = CourtCase.ColorID.fillna(-1)\n",
    "CourtCase[\"InstanceLevelID\"] = CourtCase.InstanceLevelID.fillna(-1)\n",
    "CourtCase[\"SubCategoryID\"] = CourtCase.SubCategoryID.fillna(-1)\n",
    "CourtCase[\"CasePriorityID\"] = CourtCase.CasePriorityID.fillna(-1)\n",
    "CourtCase[\"IsDetentionCase\"] = CourtCase.IsDetentionCase.fillna(0)\n",
    "CourtCase[\"IsPublicCase\"] = CourtCase.IsPublicCase.fillna(0)\n",
    "CourtCase[\"CommittedByMinor\"] = CourtCase.CommittedByMinor.fillna(0)\n",
    "CourtCase[\"GenderBasedViolence\"] = CourtCase.GenderBasedViolence.fillna(0)\n",
    "CourtCase[\"InitiatedFromAbunzi\"] = CourtCase.InitiatedFromAbunzi.fillna(0)\n",
    "CourtCase[\"SolvedFromAbunzi\"] = CourtCase.SolvedFromAbunzi.fillna(0)\n",
    "CourtCase[\"HasDetails\"] = CourtCase.HasDetails.fillna(0)\n",
    "CourtCase[\"IsExempted\"] = CourtCase.IsExempted.fillna(0)\n",
    "CourtCase[\"AttachedDate\"] = CourtCase.AttachedDate.fillna(0)\n",
    "CourtCase.drop(columns=[\"HasPassedCaseNumberAllocated\", \"CaseCode\", \"MinorVersion\", \"MajorVersion\", \"CourtID\", \"CourtCaseID\"\n",
    "                   , \"ReceiptDocumentID\",  \"ProsecutionCaseID\", \"WFActionID\"\n",
    "                   , \"NotRegisteredCaseCode\", \"WFStateID\", \"UpdatedUserID\", \"OwnerUserID\", \"PublicOwnerUserId\", 'CreatedUserID'\n",
    "                   ,'AppealedCourtCaseID', \"CountOfJudgmentPages\"\n",
    "                  ], inplace=True)\n",
    "\n",
    "CourtCase_test[\"HasRecieptDocument\"] = CourtCase_test.ReceiptDocumentID.fillna(0).apply(lambda x: 1 if x > 0 else 0)\n",
    "CourtCase_test[\"HasProsecutionCase\"] = CourtCase_test.ProsecutionCaseID.fillna(0).apply(lambda x: 1 if x > 0 else 0)\n",
    "# CourtCase_test[\"IsAppealedcase\"] = CourtCase_test.AppealedCourtCaseID.fillna(0).apply(lambda x: 1 if x > 0 else 0)\n",
    "CourtCase_test[\"ColorID\"] = CourtCase_test.ColorID.fillna(-1)\n",
    "CourtCase_test[\"InstanceLevelID\"] = CourtCase_test.InstanceLevelID.fillna(-1)\n",
    "CourtCase_test[\"SubCategoryID\"] = CourtCase_test.SubCategoryID.fillna(-1)\n",
    "CourtCase_test[\"CasePriorityID\"] = CourtCase_test.CasePriorityID.fillna(-1)\n",
    "CourtCase_test[\"IsDetentionCase\"] = CourtCase_test.IsDetentionCase.fillna(0)\n",
    "CourtCase_test[\"IsPublicCase\"] = CourtCase_test.IsPublicCase.fillna(0)\n",
    "CourtCase_test[\"CommittedByMinor\"] = CourtCase_test.CommittedByMinor.fillna(0)\n",
    "CourtCase_test[\"GenderBasedViolence\"] = CourtCase_test.GenderBasedViolence.fillna(0)\n",
    "CourtCase_test[\"InitiatedFromAbunzi\"] = CourtCase_test.InitiatedFromAbunzi.fillna(0)\n",
    "CourtCase_test[\"SolvedFromAbunzi\"] = CourtCase_test.SolvedFromAbunzi.fillna(0)\n",
    "CourtCase_test[\"HasDetails\"] = CourtCase_test.HasDetails.fillna(0)\n",
    "CourtCase_test[\"IsExempted\"] = CourtCase_test.IsExempted.fillna(0)\n",
    "CourtCase_test[\"AttachedDate\"] = CourtCase_test.AttachedDate.fillna(0)\n",
    "CourtCase_test.drop(columns=[\"HasPassedCaseNumberAllocated\", \"CaseCode\", \"MinorVersion\", \"MajorVersion\", \"CourtID\", \"CourtCaseID\"\n",
    "                   , \"ReceiptDocumentID\",  \"ProsecutionCaseID\", \"WFActionID\"\n",
    "                   , \"NotRegisteredCaseCode\", \"WFStateID\", \"UpdatedUserID\", \"OwnerUserID\", \"PublicOwnerUserId\", 'CreatedUserID'\n",
    "                   ,'AppealedCourtCaseID', \"CountOfJudgmentPages\"\n",
    "                  ], inplace=True)\n",
    "\n",
    "print(CourtCase_test.shape)\n",
    "print(CourtCase.shape)\n",
    "\n",
    "A = calculate_missing_values(CourtCase)\n",
    "drop_col = A[A[\"% of Total Values\"] > 90].index\n",
    "CourtCase = CourtCase.drop(columns=drop_col)\n",
    "CourtCase.dropna(inplace=True)\n",
    "CourtCase_test = CourtCase_test.drop(columns=drop_col)\n",
    "CourtCase_test.dropna(inplace=True)\n",
    "print(CourtCase_test.shape)\n",
    "print(CourtCase.shape)\n",
    "\n",
    "calculate_missing_values(CourtCase)\n",
    "calculate_missing_values(CourtCase_test)\n",
    "\n",
    "X = CourtCase.drop(columns=[\"DecisionDuration\"])\n",
    "Y = CourtCase[\"DecisionDuration\"]\n",
    "\n",
    "X_test = CourtCase_test.drop(columns=[\"DecisionDuration\"])\n",
    "Y_test = CourtCase_test[\"DecisionDuration\"]\n",
    "print(X.shape, Y.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DecisionPronouncementDate', 'DecisionPronouncementDateYearID',\n",
       "       'ExecutionCaseApprovedUserID', 'PaymentBankID', 'LitigationCaseID',\n",
       "       'CaseRejectionID', 'ExtraOrdinaryProcedureID', 'PreviousCourtCaseID',\n",
       "       'SpecialCaseID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_params = {'n_estimators': 200,\n",
    " 'min_samples_split': 40,\n",
    " 'min_samples_leaf': 4,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 20,\n",
    " 'learning_rate': 0.05}\n",
    "boost = GradientBoostingRegressor(**boost_params)\n",
    "\n",
    "# boost.fit(X, Y)\n",
    "# y_pred = boost.predict(X_test)\n",
    "# r2_score(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMRegressor\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb1 = LGBMRegressor(\n",
    " learning_rate =0.01,\n",
    " n_estimators=5000,\n",
    " max_depth=-1,\n",
    " min_child_weight=0,\n",
    " num_leaves = 68,\n",
    " min_child_samples = 5,\n",
    " objective= 'regression',\n",
    " subsample_for_bin = 1000,\n",
    " min_split_gain = 0,\n",
    " feature_fraction = 0.5, \n",
    " nthread=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X, dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       feature_fraction=0.5, learning_rate=0.01, max_depth=-1,\n",
       "       min_child_samples=5, min_child_weight=0, min_split_gain=0,\n",
       "       n_estimators=5000, n_jobs=-1, nthread=-1, num_leaves=68,\n",
       "       objective='regression', random_state=None, reg_alpha=0.0,\n",
       "       reg_lambda=0.0, silent=True, subsample=1.0, subsample_for_bin=1000,\n",
       "       subsample_freq=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb1.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test, dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7201467667579639"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lgb1.predict(X_test)\n",
    "r2_score(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb1.fit(train_X, train_Y)\n",
    "boost.fit(train_X, train_Y)\n",
    "\n",
    "lgb1_pred_y = lgb1.predict(test_X)\n",
    "boost_pred_y = boost.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.column_stack((lgb1_pred_y, boost_pred_y))\n",
    "final_forest = RandomForestRegressor(n_estimators=100)\n",
    "# final_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_forest.fit(train_data, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb1_pred = pd.DataFrame(lgb1_pred_y, columns=[\"lgb\"])\n",
    "boost_pred = pd.DataFrame(boost_pred_y, columns=[\"boost\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([lgb1_pred, boost_pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"lgb^2\"] = train_data[\"lgb\"] ** 2\n",
    "train_data[\"boost^2\"] = train_data[\"boost\"] ** 2\n",
    "train_data[\"boost_lgb\"] = train_data[\"boost\"] * train_data[\"lgb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb</th>\n",
       "      <th>boost</th>\n",
       "      <th>lgb^2</th>\n",
       "      <th>boost^2</th>\n",
       "      <th>boost_lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.004137</td>\n",
       "      <td>19.648007</td>\n",
       "      <td>400.165492</td>\n",
       "      <td>386.044194</td>\n",
       "      <td>393.041429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.033151</td>\n",
       "      <td>12.261492</td>\n",
       "      <td>81.597808</td>\n",
       "      <td>150.344185</td>\n",
       "      <td>110.759902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.280485</td>\n",
       "      <td>5.762632</td>\n",
       "      <td>39.444488</td>\n",
       "      <td>33.207931</td>\n",
       "      <td>36.192124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.199569</td>\n",
       "      <td>6.817287</td>\n",
       "      <td>51.833789</td>\n",
       "      <td>46.475398</td>\n",
       "      <td>49.081524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.303913</td>\n",
       "      <td>44.950460</td>\n",
       "      <td>2144.052314</td>\n",
       "      <td>2020.543859</td>\n",
       "      <td>2081.382170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lgb      boost        lgb^2      boost^2    boost_lgb\n",
       "0  20.004137  19.648007   400.165492   386.044194   393.041429\n",
       "1   9.033151  12.261492    81.597808   150.344185   110.759902\n",
       "2   6.280485   5.762632    39.444488    33.207931    36.192124\n",
       "3   7.199569   6.817287    51.833789    46.475398    49.081524\n",
       "4  46.303913  44.950460  2144.052314  2020.543859  2081.382170"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=10, min_samples_split=10,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = RandomForestRegressor(n_estimators=500, max_depth=3, min_samples_leaf=10, min_samples_split=10)\n",
    "final_model.fit(train_data, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.7691464087704594, total=   2.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.6518474195051936, total=   2.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.7250839324781942, total=   2.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    6.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ , score=0.715518434917908, total=   2.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    9.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... , score=0.6849304532686559, total=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   11.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7093053297880824"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(final_model, train_data, test_Y, cv=5, verbose=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
